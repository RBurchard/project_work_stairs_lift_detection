{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e57f6346-1c76-482b-8069-9f4321e5aa70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import skew, kurtosis\n",
    "from collections import Counter\n",
    "\n",
    "datadir = '../Collected Data/'\n",
    "\n",
    "def read_file(num):\n",
    "    dataset = pd.read_csv(datadir+'Collected Updated Labeled Data - Phase 01/participant '+ num +'.csv')\n",
    "    if 'Time' in dataset.columns:\n",
    "        dataset.drop('Time', axis=1, inplace=True)\n",
    "    if 'Start' in dataset.columns:\n",
    "        dataset.drop('Start', axis=1, inplace=True)\n",
    "    if 'End' in dataset.columns:\n",
    "        dataset.drop('End', axis=1, inplace=True)\n",
    "\n",
    "    dataset['Label'] = dataset['Label'].apply(\n",
    "        lambda x: x.lower() if x != 'Null' else x\n",
    "    )\n",
    "        \n",
    "    strings_to_replace = ['null', ' null', 'Null ', 'null ']\n",
    "    replacement_string = 'Null'\n",
    "    dataset = dataset.replace(strings_to_replace, replacement_string)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "090b19e8-fee6-4393-8996-921178ea180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_slope(data):\n",
    "    data = data.replace(np.inf, np.nan).replace(-np.inf, np.nan).dropna()\n",
    "    x = np.arange(len(data))\n",
    "    if len(x)>1:\n",
    "        slope = np.polyfit(x, data, 1)[0]\n",
    "    else: \n",
    "        slope = 0\n",
    "    return slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72c64c37-a405-437a-9130-50e2a4fc48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_interval(group):\n",
    "    start_time = group['Timestamp'].min()\n",
    "    end_time = group['Timestamp'].max()\n",
    "    elapsed_time = end_time-start_time\n",
    "    label_mode = group['Label'].mode().iloc[0] #calculating mode value to assign label\n",
    "    labeldict = Counter(group['Label']) #getting the count of each value in label\n",
    "    label_percentage = (labeldict[label_mode] / len(group['Label']) ) * 100 #calculating the percentage of values that are same as mode\n",
    "    if ((label_percentage > 79) and (elapsed_time > 7.8)): #calculating the values only if the label is atleast 80% else return and if it's more than 7 seconds and also if the interval is atleast 7.8seconds long\n",
    "        summary = {\n",
    "            'avg_accX': group['X'].mean(),\n",
    "            'min_accX': group['X'].min(),\n",
    "            'max_accX': group['X'].max(),\n",
    "            'var_accX': group['X'].var(),\n",
    "            'std_accX': np.std(group['X']),\n",
    "            'avg_accY': group['Y'].mean(),\n",
    "            'min_accY': group['Y'].min(),\n",
    "            'max_accY': group['Y'].max(),\n",
    "            'var_accY': group['Y'].var(),\n",
    "            'std_accY': np.std(group['Y']),\n",
    "            'avg_accZ': group['Z'].mean(),\n",
    "            'min_accZ': group['Z'].min(),\n",
    "            'max_accZ': group['Z'].max(),\n",
    "            'var_accZ': group['Z'].var(),\n",
    "            'std_accZ': np.std(group['Z']),\n",
    "            'avg_magnitude': group['Magnitude'].mean(),\n",
    "            'min_magnitude': group['Magnitude'].min(),\n",
    "            'max_magnitude': group['Magnitude'].max(),\n",
    "            'var_magnitude': group['Magnitude'].var(),\n",
    "            'std_magnitude': np.std(group['Magnitude']),\n",
    "            'var_pressure': group['Pressure'].var(),\n",
    "            'range_pressure': (group['Pressure'].max() - group['Pressure'].min()),\n",
    "            'std_pressure': np.std(group['Pressure']),\n",
    "            'slope_pressure': calculate_slope(group['Pressure']),\n",
    "            'kurtosis_pressure': kurtosis(group['Pressure']),\n",
    "            'skew_pressure': skew(group['Pressure']),\n",
    "            'Label': label_mode,  # Most frequent label in the interval\n",
    "        }\n",
    "        return pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "135138c0-2d18-4073-96e1-bfd9f63dd3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(num, dataset):\n",
    "    # Applying the summarize_interval function to each 2-second interval\n",
    "    interval_seconds = 8\n",
    "    result_df = dataset.groupby(dataset['Timestamp'] // interval_seconds).apply(summarize_interval)\n",
    "    # Reset index to flatten the DataFrame and remove the multi-index\n",
    "    result_df = result_df.reset_index(drop=True)\n",
    "    # Remove rows with any NaN values\n",
    "    result_df = result_df.dropna(how='any')\n",
    "    #save the preprocessed data to a new CSV file\n",
    "    result_df.to_csv(datadir+'preprocessed/preprocessed_data'+str(num)+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b324c72-6eee-407a-8967-6ef76aa865e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for i in range(1, 21):\n",
    "        preprocessing(i, read_file(f\"0{i}\" if i < 10 else str(i)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8e97e04-b064-4897-a843-efa4a4757548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "\n",
    "def merge_files(test_participant, datadir):\n",
    "    print(test_participant)\n",
    "    csv_files = glob.glob(datadir+'preprocessed/*.csv')\n",
    "\n",
    "    dfs = []\n",
    "\n",
    "    filtered_files = [f for f in csv_files if datadir+'preprocessed\\preprocessed_data'+str(test_participant)+'.csv' not in f]\n",
    "    # Loop through each CSV file and append its DataFrame to the list\n",
    "    for file in filtered_files:\n",
    "        df = pd.read_csv(file)\n",
    "        dfs.append(df)\n",
    "        #print(file)\n",
    "    # Concatenate all DataFrames in the list along rows (axis=0)\n",
    "    merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    merged_df.to_csv(datadir+'preprocessed/traindata/preprocessed_traindata'+str(test_participant)+'.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95638555-0688-47b8-a103-b21b3146b4ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "for i in range (1, 21):\n",
    "    merge_files(i, datadir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c999e8-7d6b-4174-8167-90bb255c2809",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
